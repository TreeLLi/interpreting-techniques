# Explainable AI: Interpreting Techniques

this project aims at reproducing those comtemporary widely-accepted interpreting techniques for explaining a class of complicated models Deep Neural Networks (DNNs).

I am now working on the reproduction of LIME, Local Interpretable Model-Agnostic Explanations, while alternatives like Layer-wise Relevance Propagation (LRP), DeepLIFT, Activation Maximisation, etc. are in the plan.
